{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Coyota vs Dogs\n",
    "# Import Packages\n",
    "    Import Tensorflow and the Keras classes needed to construct our model.\n",
    "    Import Numpy, Random, Mathplotlib\n",
    "    Import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5WddYOXibOds",
    "outputId": "9917f480-0016-4c6a-ac99-f3b48e8431a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set-up - Imports\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import random\n",
    "print('Set-up - Imports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "VycVSX93cvvj",
    "outputId": "fc8a1fa4-105e-4b2b-e561-35c60ff4491b"
   },
   "outputs": [],
   "source": [
    "train = os.path.join('C:/Users/lmnop/Documents/TrainSetTest/Train')\n",
    "test = os.path.join('C:/Users/lmnop/Documents/TrainSetTest/Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Data\n",
    "    How many Dog and Coyote images are in train and test folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MBW6O7udug3n",
    "outputId": "318ac504-35cb-4875-bf03-e67f6c646d41",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:/Users/lmnop/Documents/TrainSetTest/Train/dog'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f339afd16d2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_coyote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/lmnop/Documents/TrainSetTest/Test/coyote'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Total Training Dog Images {len(os.listdir(train_dog))}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Total Training Coyote Images {len(os.listdir(train_coyote))}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Total Test Dog Images {len(os.listdir(test_dog))}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:/Users/lmnop/Documents/TrainSetTest/Train/dog'"
     ]
    }
   ],
   "source": [
    "train_dog = os.path.join('C:/Users/lmnop/Documents/TrainSetTest/Train/dog')\n",
    "train_coyote = os.path.join('C:/Users/lmnop/Documents/TrainSetTest/Train/coyote')\n",
    "test_dog = os.path.join('C:/Users/lmnop/Documents/TrainSetTest/Test/dog')\n",
    "test_coyote = os.path.join('C:/Users/lmnop/Documents/TrainSetTest/Test/coyote')\n",
    "\n",
    "print(f'Total Training Dog Images {len(os.listdir(train_dog))}')\n",
    "print(f'Total Training Coyote Images {len(os.listdir(train_coyote))}')\n",
    "print(f'Total Test Dog Images {len(os.listdir(test_dog))}')\n",
    "print(f'Total Test Coyote Images {len(os.listdir(test_coyote))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the matplot parameters and take a look at a few pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNpLQH1pvB6y"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "pic_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display 8 images, 4 dogs and 4 coyotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "MM7W-FN6vFSo",
    "outputId": "fecca013-aff2-4b82-ecd1-6fcd437c3032"
   },
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_cat_pix = [os.path.join(dog_train, fname) \n",
    "                for fname in dog_train_fnames[pic_index-8:pic_index]]\n",
    "next_dog_pix = [os.path.join(coyote_train, fname) \n",
    "                for fname in coyote_train_fnames[pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off')\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model \n",
    "    Resizing the images to 150 x 150, R,G,B\n",
    "    We will stack 3 {convolution + relu + maxpooling} modules. \n",
    "    Our convolutions operate on 3x3 windows and our maxpooling layers operate on 2x2 windows. \n",
    "    Our first convolution extracts 16 filters, the following one extracts 32 filters, and the last one extracts 64 filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXRweQ_vBq3u"
   },
   "outputs": [],
   "source": [
    "img_input = layers.Input(shape=(150, 150, 3))\n",
    "\n",
    "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use flatten to make our model a binary classification problem and fully connect the layers and output the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjxj4m4oBvvD"
   },
   "outputs": [],
   "source": [
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "6ZQNvU3XB11z",
    "outputId": "ae230e08-d4ed-4afd-8a6b-26ae88552585",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model with the binary_crossentropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQstOZKICZ3k"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "    Rescaling images and training in batches of 20 using val_datagen generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "fBqkpwl3EB9c",
    "outputId": "f97d6e1d-4758-4fd3-a1f2-a90fbe110c7b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train,  \n",
    "        target_size=(150, 150),  \n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        test,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=15,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Intermediate Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "visualization_model = Model(img_input, successive_outputs)\n",
    "\n",
    "cat_img_files = [os.path.join(dog_train, f) for f in dog_train_fnames]\n",
    "dog_img_files = [os.path.join(coyote_train, f) for f in coyote_train_fnames]\n",
    "img_path = random.choice(cat_img_files + dog_img_files)\n",
    "\n",
    "img = load_img(img_path, target_size=(150, 150))\n",
    "x = img_to_array(img) \n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "x /= 255\n",
    "\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "  if len(feature_map.shape) == 4:\n",
    "    n_features = feature_map.shape[-1]\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = feature_map.shape[1]\n",
    "    # We will tile our images in this matrix\n",
    "    display_grid = np.zeros((size, size * n_features))\n",
    "    for i in range(n_features):\n",
    "      # Postprocess the feature to make it visually palatable\n",
    "      x = feature_map[0, :, :, i]\n",
    "      x -= x.mean()\n",
    "      x /= x.std()\n",
    "      x *= 64\n",
    "      x += 128\n",
    "      x = np.clip(x, 0, 255).astype('uint8')\n",
    "      # We'll tile each filter into this big horizontal grid\n",
    "      display_grid[:, i * size : (i + 1) * size] = x\n",
    "    # Display the grid\n",
    "    scale = 20. / n_features\n",
    "    plt.figure(figsize=(scale * n_features, scale))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Accuracy and Loss for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a list of accuracy results on training and validation data\n",
    "# sets for each training epoch\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prevent Overfitting\n",
    "    using data augmentation and add dropout to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply horizontal flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = image_gen.flow_from_directory(batch_size=128,\n",
    "                                               directory=train,\n",
    "                                               shuffle=True,\n",
    "                                               target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply zoom augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = image_gen.flow_from_directory(batch_size=128,\n",
    "                                               directory=train,\n",
    "                                               shuffle=True,\n",
    "                                               target_size=(150, 150))\n",
    "\n",
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_train = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=45,\n",
    "                    width_shift_range=.15,\n",
    "                    height_shift_range=.15,\n",
    "                    horizontal_flip=True,\n",
    "                    zoom_range=0.5\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = image_gen_train.flow_from_directory(batch_size=128,\n",
    "                                                     directory=train,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(150, 150),\n",
    "                                                     class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize how a single image would look five different times when passing these augmentations randomly to the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_val = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_gen = image_gen_val.flow_from_directory(batch_size=128,\n",
    "                                                 directory=test,\n",
    "                                                 target_size=(150, 150),\n",
    "                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Network with Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', \n",
    "           input_shape=(150, 150 ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_new.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_new.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=15,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Evaluating Accuracy and Loss for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(15)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TestFile.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
